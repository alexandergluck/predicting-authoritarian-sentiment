{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f06c3d5-37cf-4e9e-893e-e4d4672aa6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ccf1e1-7e2f-4cbc-bd1a-2dcd55c5d636",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../raw_data/WVS_TimeSeries_4_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wvs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../raw_data/WVS_TimeSeries_4_0.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../raw_data/WVS_TimeSeries_4_0.csv'"
     ]
    }
   ],
   "source": [
    "wvs = pd.read_csv('../raw_data/WVS_TimeSeries_4_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf871342-c290-4235-9fae-aecf49843d5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem Statement ##\n",
    "\n",
    "Authoritarian backsliding has been one of the most concerning trends among the Democratic world over the last several years. In order to gain and keep power, authoritarian leaders need followers who support them and what they stand for, at least at first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ccf8eb-38e1-40fe-87a8-8209d406e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f3d4c-09b6-4646-a711-ebf567ce22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe65af-9f67-42e7-9ed4-e475a2ebdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs.COUNTRY_ALPHA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90861ced-415c-4a99-b276-e23c088f042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842d782-781b-461b-a958-9ddba264729b",
   "metadata": {},
   "source": [
    "There are a number of pre-engineered aggregate variables at the end of the dataset. Each of these has the prefix 'Y'. I'm not inclined to use them in my models because the literature on which questions they aggregate, and the methodology for doing so, isn't great. There also seems to be a fair number of null values. As I searched through these, I was somewhat interested in variable **Y011A**, which is described in the data dictionary as \"AUTHORITY\". After some further digging, however, I discovered that this statistic is meant to measure the respondents defiance of authority, rather than inclination towards authoritarian values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740631e1-8374-4f65-a945-1ac017f16244",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(wvs['Y011A'], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205b241-fcf4-452b-b268-4d3c434192a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs.Y011A.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b99f3-acb3-4d0f-a355-055d5d487d8a",
   "metadata": {},
   "source": [
    "The data for the survey has thus far been collected in seven waves, with each wave taking a few years to complete. The questions asked and the countries participating have changed and expanded over the course of each successive wave. Variable **S002VS** indicates the wave during which each interview was conducted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ff627-3eca-4ef1-b5a3-6f02cff1a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs['S002VS'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b49c83-3056-4977-882a-dc0ef8c98d84",
   "metadata": {},
   "source": [
    "My initial plan was to create time series data by aggregating by year and country all the way back to the first wave, which started in 1981. One quick look at variable **S020**, which indicates the year in which each interview was conducted, shows why this won't be possible. There are big gaps in time between waves 1 and 2 (1985-1988), as well as between waves 2 and 3 (1992-1994).\n",
    "\n",
    "Luckily, this issue dissapates thereafter, with successive waves following wave 3 starting almost as soon as the previous wave completes. As a result, I should be able to create my time series data starting with the first year of wave 3 in 1995. Starting with wave 3 does have some additional benefits, as wave 3 marked a significant expansion in the scope of the survey both in terms of the questions asked and the countries included.  \n",
    "\n",
    "There is still a one year gap in 2015. Once I have the data in the shape I want it I'll consider various methods of interpolation in order to fill the gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8babb-f08e-4e18-b57f-0ec1e8d202f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs['S020'].value_counts(sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27263545-5aa8-4bb3-9285-bd45c31e3df9",
   "metadata": {},
   "source": [
    "I'll start constructing the dataset for my time series model by removing interviews collected prior to 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a4578-d80f-4fb7-8231-c03946b6e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts = wvs[wvs['S020'] >= 1995].copy()\n",
    "wvs_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8190be-4806-47b2-90df-86c3938691ee",
   "metadata": {},
   "source": [
    "Here is a list of countries included in the data starting with wave 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd02cd4-779c-4057-ac77-c85291603052",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['COUNTRY_ALPHA'][wvs_ts['S002VS'] == 3].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef20887-2aa8-4fda-88fb-33e7c8f7b8e3",
   "metadata": {},
   "source": [
    "## Sorting Countries Into Regions\n",
    "\n",
    "Unfortunately, I'm discovering that when breaking things down to the country level there are more gaps year by year, with most countries completing their interviews for each wave in a single year, and some countries not involved in every wave. In order to create a dataset I can use for time series I'll need to group the countries into **regions**, so that I have data for every year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55b1f0-b11d-4e17-a11e-7063570aa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waves_years(country_code):\n",
    "    country_df = wvs_ts[['COUNTRY_ALPHA', 'S002VS', 'S020']][wvs_ts['COUNTRY_ALPHA'] == country_code]\n",
    "    unique_values = country_df.drop_duplicates(subset = 'S020').sort_values(by='S020')\n",
    "    return unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244b4bb-539c-417f-ade1-1e4537d8e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves_years('ROU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fae9c-9213-4abb-8a84-d5a45ee7d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves_years('USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062d2a1-d677-4d65-9f9b-4b585b424c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves_years('BRA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ea7d3-3137-4870-a678-84a9acdbaf34",
   "metadata": {},
   "source": [
    "### Limitations of This Approach\n",
    "##### ...Plus one Benefit\n",
    "\n",
    "I'm a bit disappointed, as i was looking forward to seeing the relationships between countries in a given region. I also see further limitations here. Each annual data point from a given region will now be from a mostly different mix of countries than the previous annual data point. This could obscure trends, and cause other issues. Overall I am not that optimistic about how this change will affect the quality of the data I get from my time-series model. \n",
    "\n",
    "One positive is that by going this route I can include data from countries that were added to the survey after wave 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93c861-d5bd-48f0-b7b5-ea11665073e9",
   "metadata": {},
   "source": [
    "### Defining **Regions**\n",
    "\n",
    "I'll define 6 regions for the purposes of this variable:\n",
    "1) Africa\n",
    "2) Asia Pacific\n",
    "3) Middle-East/North Africa\n",
    "4) Eastern Europe\n",
    "5) Western Europe/North America\n",
    "6) Latin America/Caribbean\n",
    "\n",
    "I've chosen these regions to be *relatively* idealogically and geographically coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff438d9-7cc3-4e01-b382-37af7ad4c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {\n",
    "    'Africa': ['AGO', 'BEN', 'BWA', 'BFA', 'BDI', 'CMR', 'CPV', 'CAF', 'TCD',\n",
    "               'COM', 'COG', 'CIV', 'DJI', 'GNQ', 'ERI', 'ETH', 'GAB', 'GMB',\n",
    "               'GHA', 'GIN', 'GNB', 'KEN', 'LSO', 'LBR', 'MDG', 'MWI', 'MLI',\n",
    "               'MRT', 'MUS', 'MYT', 'MOZ', 'NAM', 'NER', 'NGA', 'STP', 'REU',\n",
    "               'RWA', 'ST', 'SEN', 'SYC', 'SLE', 'SOM', 'ZAF', 'SSD', 'SHN',\n",
    "               'SDN', 'SWZ', 'TZA', 'TGO', 'UGA', 'COD', 'ZMB', 'TZA', 'ESH',\n",
    "               'ZWE'],\n",
    "    'Asia Pacific': ['AFG', 'AUS', 'BGD', 'BTN', 'BRN', 'KHM', 'CHN', 'CXR', 'CCK',\n",
    "                     'IOT', 'FJI', 'PYF', 'GUM', 'HKG', 'IND', 'IDN', 'JPN', 'KAZ',\n",
    "                     'PRK', 'KOR', 'KGZ', 'LAO', 'MAC', 'MYS', 'MDV', 'MHL', 'FSM',\n",
    "                     'MNG', 'MMR', 'NPL', 'NZL', 'NFK', 'MNP', 'PAK', 'PLW', 'PNG',\n",
    "                     'PHL', 'PCN', 'WSM', 'SGP', 'SLB', 'LKA', 'TWN', 'THA', 'TLS',\n",
    "                     'TUV', 'VNM', 'UZB', 'TJK'],\n",
    "    'Middle East/North Africa': ['DZA', 'BHR', 'EGY', 'IRN', 'IRQ', 'ISR', 'JOR', 'KWT', 'LBN',\n",
    "                                 'LBY', 'MLT', 'MAR', 'OMN', 'PSE', 'QAT', 'SAU', 'SYR', 'TUN',\n",
    "                                 'ARE', 'YEM', 'TUR', 'ARM', 'AZE'],\n",
    "    'Eastern Europe': ['BLR', 'BGR', 'CZE', 'GEO', 'HUN', 'MDA', 'POL', 'ROU', 'RUS', \n",
    "                       'SVK', 'UKR', 'ALB', 'BIH', 'HRV', 'EST', 'LTU', 'LVA', 'MKD',\n",
    "                       'MNE', 'SRB', 'SVN'],\n",
    "    'Western Europe/North America': ['AUT', 'BEL', 'CAN', 'DNK', 'FIN', 'FRA', 'DEU', 'GRC', 'ISL',\n",
    "                                     'ITA', 'LUX', 'NLD', 'NOR', 'PRT', 'ESP', 'SWE', 'CHE', 'GBR',\n",
    "                                     'USA', 'IRL', 'CYP', 'MCO', 'AND', 'NIR'],\n",
    "    'Latin America/Caribbean': ['ATG', 'ARG', 'BHS', 'BRB', 'BLZ', 'BOL', 'BRA', 'CHL', 'COL',\n",
    "                                'CRI', 'CUB', 'DMA', 'DOM', 'ECU', 'SLV', 'GRD', 'GTM', 'HTI',\n",
    "                                'HND', 'JAM', 'MEX', 'NIC', 'PAN', 'PRY', 'PER', 'KNA', 'LCA',\n",
    "                                'VCT', 'SUR', 'TTO', 'URY', 'VEN', 'GUY', 'GUF', 'TCO', 'CYM',\n",
    "                                'PRI']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe200860-4970-44b9-a1f7-af219586596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(country_code):\n",
    "    for region, countries in region_dict.items():\n",
    "        if country_code in countries:\n",
    "            return region\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "wvs_ts['region'] = [get_region(country_code) for country_code in wvs_ts['COUNTRY_ALPHA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1195c-54a5-4c97-992c-a60c3004f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['region'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb01b1-8901-4c62-af03-7b18fb0df499",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Engineering an **Authoritarianism Index** to Serve as My Target Variable\n",
    "I'll engineer a variable that I'll term the **Authoritarianism Index** to serve as the **y** variable for my models. I'll use this as the **y** for both my time series model and my traditional model.\n",
    "\n",
    "This variable will be a composite score based on each respondent's answers to several questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7434d9e-f7e5-4d8d-b08b-0798a9623c9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Questions to include\n",
    "\n",
    "In order for a question to be considered for inclusion in my **Authoritarianism Index**, it needs to meet the following criteria:\n",
    "- The question must be directly related to values associated with Authoritarianism\n",
    "- The question must appear in all waves of the survey included in the model (waves 3-7)\n",
    "- The response scale for the question must be ordinal in nature\n",
    "\n",
    "Based on these criteria, I selected the following four questions to be included in the **Authoritarianism Index** variable:\n",
    "| Question ID | Question Description | Response Scale | Directionality |\n",
    "|---|---|---|---|\n",
    "| A042 | \"Here is a list of qualities that children can be encouraged to learn at home. Which, if any, do you consider to be especially important? Please choose up to five\" (**Obedience**) | 0 (not mentioned) to 1 (important) | Positive |\n",
    "| E018 | \"I'm going to read out a list of various changes in our way of life that might take place in the near future. Please tell me for each one, if it were to happen, whether you think it would be a good thing, a bad thing, or don't you mind?\" (**Greater respect for authority**) | 1 (good thing) to 3 (bad thing) | Negative |\n",
    "| E114 | \"I'm going to describe various types of political systems and ask what you think about each as a way of governing this country. For each one, would you say it is a very good, fairly good, fairly bad or very bad way of governing this country?\" (**Having a strong leader**) | 1 (very good) to 4 (very bad) | Negative |\n",
    "| E116 | \"I'm going to describe various types of political systems and ask what you think about each as a way of governing this country. For each one, would you say it is a very good, fairly good, fairly bad or very bad way of governing this country?\" (**Having the army rule**) | 1 (very good) to 4 (very bad) | Negative |\n",
    "\n",
    "\n",
    "*Scales determined with reference to https://www.worldvaluessurvey.org/WVSOnline.jsp*\n",
    "\n",
    "***Note:*** *The directionality of the scales is at times inconsistent. Eg. for question **A042** the value associated with the positive answer is higher, while for the other three questions it is lower. I've noted the directionality of the scales in the above table. I'll need to account for that when engineering my composite variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb5246-1aa8-4db5-b5d1-42e1863b78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['A042'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4aa028-6475-46ce-ad99-b25013157a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['E018'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a760b6-109e-4fd0-b1d7-8436e32c7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['E114'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22722d81-8e24-4609-84ba-ce6f19bd4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['E116'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc8841-cab9-463a-b198-f1ca0820faf2",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Notice that each variable above has a number of negative values associated with it. Each of these negative numbers corresponds to a different type of **missing data**, which are as follows:\n",
    "- **-1**: Respondent answered \"Don't know\" to question\n",
    "- **-2**: Respondent refused or otherwise provided \"No answer\" to question\n",
    "- **-3**: Question \"Not applicable\". Subject screened out of question by virtue of a response to a filter question\n",
    "- **-4**: Question was \"Not asked in survey\"\n",
    "    - ***Note**: My expectation was that this related to differences in questions asked from one wave of the survey to another. As I specifically chose questions based on whether or not they appeared in all waves, I did not expect to see many of these. The fact that there are still a number of missing values of this type belies that assumption.*\n",
    "- **-5**: \"Missing: other\"\n",
    "\n",
    "I want to draw special attention to type **-1** here. In contrast to the other missing value types, these are not true *missings*, as the respondents in these cases were asked the question and provided an answer of a kind. It is reasonable to read a response of \"I don't know\" as a neutral response to many of these questions, particularly since respondents are often not offered a **neutral option** as one of the response choices. I'll handle these by creating that **neutral option** at the midpoint, (eg. a four point scale becomes a five point scale with the third option as **neutral**) and assigning items currently coded as **-1** to it. I'll do this as part of a number of adjustments I intend to make to the scales of these variables, in preparation for combining them into my **Authoritarianism Index** variable.\n",
    "\n",
    "I considered doing the same for missing value type **-2**, but ultimately decided it could not be justified. Neutrality is one possible explanation for why a respondent might not answer a question. Another might be that the respondent feels ashamed of their opinion, or fears the judgement of the interviewer. There could be many other explanations. With no answer given, there is not enough information to determine the respondent's intent. Values of **-2** will therefore be recoded as NAs along with missing value types **-3**, **-4**, and **-5**.\n",
    "\n",
    "For the purpose of constructing the **Authoritarianism Index** variable, observations will only be dropped if they have NAs for all four of the component questions. Otherwise, their **Authoritarianism Index** will be calculated using the available responses, and scaled to match the rest of the data.\n",
    "\n",
    "*Meaning of missing values detailed in **WVS-7 Master Questionnaire 2017-2020 English.pdf**, which can be downloaded from https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed55a5-80a9-45c2-bc7f-7dc6442fa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_to_na(var):\n",
    "    missings = [-2, -3, -4, -5]\n",
    "    return var.replace(missings, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3df764-6ad9-46bc-968d-f3fc1fc6b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aut_index_comp_qs = ['A042', 'E018', 'E114', 'E116']\n",
    "\n",
    "for q in aut_index_comp_qs:\n",
    "    wvs_ts[q] = missing_to_na(wvs_ts[q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041f4f5-6099-4b61-b645-e0df39f9b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['E018'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc5654-6fe1-4c4a-bf95-1d75f4cec0ed",
   "metadata": {},
   "source": [
    "### Standardizing Ordinal Scales For the Component Variables\n",
    "\n",
    "I'll need to create a function next to standardize the ordinal scales for each of the component variables that will make up the **Authoritarianism Index**. The adjusted scales should satisfy the following requirements:\n",
    "1) The scales should have the same endpoints, so that summing them gives each component variable equal weight in the derived variable\n",
    "2) The scales should all be directionally the same, meaning that positive and negative responses are on the same end of the scale for each variable\n",
    "3) The scales should have an odd number of potential values, allowing there to be a midpoint that corresponds to a neutral value (*See **Handling Missing Values** above*)\n",
    "\n",
    "In order to satisfy these requirements, I'll create a function that adjusts the scale for each of the above questions to be a five point scale from -2 to 2, where -2 indicates a strongly negative response to the question, and 2 being a strongly positive response. \"Don't know\" responses, currently coded as -1, will be recoded as 0\n",
    "\n",
    "I'll reuse this function later to rescale other questions, some of which are on an eight or ten point scale, so I'll include that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e36b5-f49f-49a3-b9e8-aed7f3a02182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_adjuster(var, direction='positive'):\n",
    "    orig_scale = var.max()\n",
    "    if direction == 'positive':\n",
    "        if orig_scale == 1:\n",
    "            return var.map({-1: 0, 0: -2, 1: 2})\n",
    "        elif orig_scale == 2:\n",
    "            return var.map({-1: 0, 1: -2}) # 2 (strong positive) in this case would stay the same\n",
    "        elif orig_scale == 3:\n",
    "            return var.map({-1: 0, 1: -2, 2: 0, 3: 2})\n",
    "        elif orig_scale == 4:\n",
    "            return var.map({-1: 0, 1: -2, 2: -1, 3: 1, 4: 2})\n",
    "        elif orig_scale == 8:\n",
    "            return var.map({-1: 0, 1: -4, 2: -3, 3: -2, 4: -1, 5: 1, 6: 2, 7: 3, 8: 4})\n",
    "        else:\n",
    "            return var.map({-1: 0, 1: -5, 2: -4, 3: -3, 4: -2, 5: -1, 6: 1, 7: 2, 8: 3, 9: 4, 10: 5})\n",
    "    else:\n",
    "        if orig_scale == 1:\n",
    "            return var.map({-1: 0, 0: 2, 1: -2})\n",
    "        elif orig_scale == 2:\n",
    "            return var.map({-1: 0, 1: 2, 2: -2})\n",
    "        elif orig_scale == 3:\n",
    "            return var.map({-1: 0, 1: 2, 2: 0, 3: -2})\n",
    "        elif orig_scale == 4:\n",
    "            return var.map({-1: 0, 1: 2, 2: 1, 3: -1, 4: -2})\n",
    "        elif orig_scale == 8:\n",
    "            return var.map({-1: 0, 1: 4, 2: 3, 3: 2, 4: 1, 5: -1, 6: -2, 7: -3, 8: -4})\n",
    "        else:\n",
    "            return var.map({-1: 0, 1: 5, 2: 4, 3: 3, 4: 2, 5: 1, 6: -1, 7: -2, 8: -3, 9: -4, 10: -5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8e70b-32dd-4d9e-8e07-3b149f61351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_scaled_qs = ['E018', 'E114', 'E116']\n",
    "\n",
    "for q in negative_scaled_qs:\n",
    "    wvs_ts[q] = scale_adjuster(wvs_ts[q], direction='negative')\n",
    "    \n",
    "wvs_ts['A042'] = scale_adjuster(wvs_ts['A042'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e9d15-77c9-4e2b-b0af-0842132c4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['E114'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fc108-d147-4c11-b8bb-b2f5065595b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating the **Authoritarianism Index** Variable\n",
    "\n",
    "Finally, I'll create the **Authoritarianism Index** variable itself. I'll do this by summing the responses to the individual questions, then dividing by the number of responses used in the calculation. In this way, values generated from respondents for whom there were missing responses to one or more of the component questions will be on the same scale as values generated from all four component questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a363a-8d27-4247-af63-2fcc3d414b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_composite(components):\n",
    "    components_notna = []\n",
    "    \n",
    "    for component in components:\n",
    "        if not np.isnan(component):\n",
    "            components_notna.append(component)\n",
    "    \n",
    "    if len(components_notna) > 0:\n",
    "        composite = sum(components_notna) / len(components_notna)\n",
    "    else:\n",
    "        composite = np.nan\n",
    "    \n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5cb8b7-ea29-4cc1-95e6-b714b3b83019",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['authoritarianism_index'] = [make_composite(row) for row in wvs_ts[aut_index_comp_qs].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b27f1-eea2-485e-a1ac-39ee1c5443dc",
   "metadata": {},
   "source": [
    "We can see that values for the **Authoritarianism Index** are on the same -2 to 2 scale as the individual components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68257f7-3c4f-4364-bd6b-95a656f27f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts[['authoritarianism_index']].value_counts(sort=False).sort_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ccdcff-3801-4ea0-b36c-88849f9b8666",
   "metadata": {},
   "source": [
    "And by engineering the variable in the way that I did, I've cut way down on null values without having to eliminate observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d2f83-3c80-48ea-a58b-8d5c9093ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['authoritarianism_index'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ad284-56a3-46d6-a6c0-133fb26a4e2b",
   "metadata": {},
   "source": [
    "I will have to drop these few observations from my dataset prior to modelling, but I'm quite satisfied with how little data will be lost at this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8eebc-b606-41fc-8187-9cb297780797",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts = wvs_ts[wvs_ts['authoritarianism_index'].notna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9d75a-df53-4137-a212-753da0c8d4f1",
   "metadata": {},
   "source": [
    "List of steps in any order:\n",
    "- **X** figure out what to do with null values \n",
    "- **X** create y (authoritarianism index) from the questions above \n",
    "- **X** make list of secondary questions to use in X \n",
    "- think about how to incorporate a 'freedom index', perhaps as a target value, as an alternative to time series\n",
    "- **X** figure out how to divide world into regions\n",
    "    - then do it\n",
    "- group by year\n",
    "- use interpolation to fill in missing year 2015\n",
    "- do some of the time series EDA stuff\n",
    "- make lots of visualizations\n",
    "- construct a time series model, probably RNN, but should also do a simpler model\n",
    "- write out problem statement\n",
    "- write out methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76e566-9e51-475c-9402-1543fcd4e640",
   "metadata": {},
   "source": [
    "## Other Potentially Correlated Questions\n",
    "\n",
    "The questions on the list below do not address **Authoritarianism** directly, but rather concern other values that may be correlated with authoritarian thinking. These will be the X variables for my regression model, and some may be included as secondary variables in my time series model as well. I'll be very interested in which ones correlate most highly with my **Authoritarianism Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca45f25d-25d1-4aff-8b6e-89c83e2fec92",
   "metadata": {},
   "source": [
    "| Question ID | Question Description | Response Scale | Directionality |\n",
    "|---|---|---|---|\n",
    "| A004, A005, A006 | \"For each of the following aspects, indicate how important it is in your life\" (**Politics, Work, Religion**) | 1 (very important) to 4 (Not at all important) | Negative |\n",
    "| A008 | \"Taking all things together, would you say you are:\" (**Happiness**) | 1 (very happy) to 4 (not at all happy) | Negative |\n",
    "| A029, A030, A032, A034, A035, A039, A040, A041 | \"Here is a list of qualities that children can be encouraged to learn at home. Which, if any, do you consider to be especially important? Please choose up to five\" (**Independence, Hard work, Feeling of responsibility, imagination, tolerance and respect for other people, determination/perseverance, religious faith, unselfishness**) | 0 (not mentioned) to 1 (important) | Positive |\n",
    "| A124_02, 03, 06, 07, 08, 09, 12, 17 | \"On this list are various groups of people. Could you please mention any that you would not like to have as neighbors?\" (**People of a different race, Heavy drinkers, Immigrants/foreign workers, People who have AIDS, Drug addicts, Homosexuals, People of a different religion, Gypsies**) | 0 (not mentioned) to 1 (mentioned) | Positive |\n",
    "| A165 | \"Generally speaking, would you say that most people can be trusted or that you need to be very careful in dealing with people?\" | 1 (Most people can be trusted) to 2 (Need to be very careful) | Negative |\n",
    "| A170 | \"All things considered, how satisfied are you with your life as a whole these days?\" | 1 (Dissatisfied) to 10 (Satisfied) | Positive |\n",
    "| D054 | \"One of my main goals in life has been to make my parents proud\" | 1 (Strongly agree) to 4 (Strongly disagree) | Negative |\n",
    "| D059 | \"Men make better political leaders than women do\" | 1 (Strongly agree) to 4 (Strongly disagree) | Negative |\n",
    "| D060 | \"University is more important for a boy than for a girl\" | 1 (Strongly agree) to 4 (Strongly disagree) | Negative |\n",
    "| E003 | \"If you had to choose, which one of the things on this card would you say is most important?\" | **Categorical**: 1 = 'Maintaining order in the nation', 2 = 'Giving people more say in important government decisions', 3 = 'Fighting rising prices', 4 = 'Protecting freedom of speech' | Not Applicable |\n",
    "| E012 | \"Of course, we all hope that there will not be another war, but if it were to come to that, would you be willing to fight for your country?\" | 0 (No) to 1 (Yes) | Positive |\n",
    "| E015, E016 | \"I'm going to read out a list of various changes in our way of life that might take place in the near future. Please tell me for each one, if it were to happen, whether you think it would be a good thing, a bad thing, or don't you mind?\" (**Less importance placed on work, More emphasis on technology**) | 1 (good thing) to 3 (bad thing) | Negative |\n",
    "| E023 | \"How interested would you say you are in politics?\" | 1 (Very interested) to 4 (Not at all interested) | Negative |\n",
    "| E069_01, 02, 04, 05, 06, 10, 11, 12, 13, 14, 15 | \"I am going to name a number of organizations. For each one, could you tell me how much confidence you have in them\" (**Churches, Armed Forces, Labour Unions, Police, Television, The Government, Political Parties, Major Companies, Environmental Protection Movement, Women's Movement**) | 1 (A great deal) to 4 (None at all) | Negative |\n",
    "| F028 | \"Apart from weddings, funerals and christenings, about how often do you attend religious services these days?\" | 1 (More than once a week) to 8 (Never, practically never) | Negative |\n",
    "| F063 | \"How important is God in your life?\" | 1 (Not at all important) to 10 (Very important) | Positive |\n",
    "| F116, F117, F118, F119, F120, F121, F122, F123 | \"Please tell me for each of the following actions whether you think it can always be justified, never be justified, or something in between\" (**Cheating on taxes, Someone accepting a bribe, Homosexuality, Prostitution, Abortion, Divorce, Euthanasia, Suicide**) | 1 (Never justifiable) to 10 (Always justifiable) | Positive |\n",
    "\n",
    "***Note**: Response scales are **ordinal** unless otherwise specified*\n",
    "\n",
    "*Scales determined with reference to https://www.worldvaluessurvey.org/WVSOnline.jsp*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd11bdc-8b3f-4b82-b011-b736fd6552ba",
   "metadata": {},
   "source": [
    "## Demographic Variables\n",
    "\n",
    "I'll also incorporate some demographic variables into the regression model. Observations in the time series model will be aggregates by year and region of the world, so it won't make sense to use individual demographic data in that model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4a600-b32f-4880-8ffa-9e966e4082d5",
   "metadata": {},
   "source": [
    "| Variable ID | Variable Description | Response Scale | Directionality | Model |\n",
    "|---|---|---|---|---|\n",
    "| X001 | sex | **Categorical**: 1 = male, 2 = female | NA | Regression |\n",
    "| X003 | Age (at time of interview) | **Numeric** | NA | Regression |\n",
    "| X007 | Marital status | **Categorical**: 1 = 'Married', 2 = 'Living together', 3 = 'Divorced', 4 = 'Separated', 5 = 'Widowed', 6 = 'Single' | NA | Regression |\n",
    "| X011 | Number of children | **Numeric** | NA | Regression |\n",
    "| X025R | Education level (Recoded into three groups) | 1 (Lower) to 3 (Higher) | Positive | Regression |\n",
    "| X028 | Employment status | **Categorical**: 1 = 'Full time (> 30hr/wk)', 2 = 'Part time (< 30hr/wk)', 3 = 'Self employed', 4 = 'Retired/pensioned', 5 = 'Housewife not otherwise employed', 6 = 'Student', 7 = 'Unemployed', 8 = 'Other' | NA | Regression |\n",
    "| X045 | Social class (subjective/self described) | 1 (Upper class) to 5 (Lower class) | Negative | Regression |\n",
    "| X047R_WVS | Income level (subjective, recoded into three groups) | 1 (low) to 3 (high) | Positive | Regression |\n",
    "| COUNTRY_ALPHA | Country of Respondent | Categorical: Three-Letter Country Code | NA | Time-Series |\n",
    "| S002VS | Survey Wave | Numeric | NA | Time-Series |\n",
    "| S020 | Year of Interview | Numeric/Datetime | NA | Time-Series |\n",
    "\n",
    "***Note**: Response scales are **ordinal** unless otherwise specified*\n",
    "\n",
    "*Scales determined with reference to https://www.worldvaluessurvey.org/WVSOnline.jsp*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bbfc5-cf95-426a-8f6e-0d2b62610304",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transforming X Variables\n",
    "I'll do the same two transformations on these variables as I did for the component variables of the **Authoritarianism Index**:\n",
    "1) Handling Missing Values\n",
    "2) Standardizing Ordinal Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1226863-1a54-487d-a7e8-a428356ca665",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scaled_qs = ['A029', 'A030', 'A032', 'A034', 'A035', 'A039', 'A040', 'A041',\n",
    "                      'A124_02', 'A124_03', 'A124_06', 'A124_07', 'A124_08', 'A124_09',\n",
    "                      'A124_12', 'A124_17', 'A170', 'E012', 'F063', 'F116', 'F117',\n",
    "                      'F118', 'F119', 'F120', 'F121', 'F122', 'F123', 'X025R', 'X047R_WVS']\n",
    "\n",
    "negative_scaled_qs = ['A004', 'A005', 'A006', 'A008', 'A165', 'D054', 'D059', 'D060',\n",
    "                      'E015', 'E016', 'E023', 'E069_01', 'E069_02', 'E069_04', 'E069_05',\n",
    "                      'E069_06', 'E069_10', 'E069_11', 'E069_12', 'E069_13', 'E069_14',\n",
    "                      'E069_15', 'F028', 'X045']\n",
    "\n",
    "all_ordinal_qs = positive_scaled_qs + negative_scaled_qs\n",
    "\n",
    "non_ordinal_qs = ['E003', 'X001', 'X007', 'X028', 'COUNTRY_ALPHA', 'S002VS', 'S020']\n",
    "\n",
    "all_qs = all_ordinal_qs + non_ordinal_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b430605-9e19-440e-ab1f-d68b56f784b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in all_ordinal_qs:\n",
    "    wvs_ts[q] = missing_to_na(wvs_ts[q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2e27f-1513-4c85-9d16-2555d08704b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in negative_scaled_qs:\n",
    "    wvs_ts[q] = scale_adjuster(wvs_ts[q], direction='negative')\n",
    "    \n",
    "for q in positive_scaled_qs:\n",
    "    wvs_ts[q] = scale_adjuster(wvs_ts[q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b87e1-6341-471d-981f-ba4a87fd3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_ts['X047R_WVS'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f423da-2430-497f-a127-b532b8a97e57",
   "metadata": {},
   "source": [
    "## Modelling Dataset\n",
    "\n",
    "I'll now create my base modelling dataset by combining my two engineered variables ('**region**' and '**authoritarianism_index**') with the other variables I've selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb451b2-c5b7-4a7a-aaee-66dfa64a2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_vars = ['region', 'authoritarianism_index']\n",
    "all_vars = engineered_vars + all_qs\n",
    "\n",
    "wvs_model = wvs_ts[all_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d158ba-ccf1-47e6-adce-38873499fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438a293-9d1e-42cb-b1aa-73dd457924fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_model.to_csv('./data/wvs_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8388e-26a9-4766-9529-781ca2faec61",
   "metadata": {},
   "source": [
    "This is the point where the shape of the data for my regression and time-series models will begin to diverge. I'll continue the process of shaping and preparing the data for modelling in the next two notebooks on EDA and data visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
